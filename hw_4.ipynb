{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS82 - Introduction to Machine Learning\n",
    "\n",
    "## Homework 4\n",
    "\n",
    "\n",
    "\n",
    "### Submission\n",
    "\n",
    "email a completed copy of this notebook to danny@ktbyte.com with subject:\n",
    "`[CS82] HW4 - Student Name`\n",
    "\n",
    "## Description\n",
    "\n",
    "To complete this homework you will need to read:\n",
    "* [Handout 4](https://content.ktbyte.com/cs82/20sp/handout/4.html)\n",
    "* [Workshop 4](https://content.ktbyte.com/cs82/20sp/workshop/ws_4.ipynb)\n",
    "* [Handout 5](https://content.ktbyte.com/cs82/20sp/handout/5.html)\n",
    "\n",
    "**Tasks** are to be performed and their output saved\n",
    "**Questions** are to be answered and their output saved\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK\n",
    "\n",
    "* Create a linear regression model without a bias (bias of 0) using the closed form approach for the dataset listed below and evaluate it using R^2 metric. \n",
    "* Create a linear regression model for the same dataset using sklearn and calculate r^2 score using sklearn build-in function. Make sure you don't fit the intercept.\n",
    "* Compare the two model's coefficients and scores\n",
    "\n",
    "The closed-form coefficients of a multi-variate linear regression model are calculated by the formula. \n",
    "$$\n",
    "y=m_1x_1+\\dots+m_nx_n\\\\\n",
    "y=X\\times m\\\\\n",
    "m=(X^TX)^{-1}X^Ty\n",
    "$$\n",
    "\n",
    "Where $X^T$ is `np.transpose(X)`\n",
    "\n",
    "and $X^{-1}$ is `np.linalg.inv(X)`\n",
    "\n",
    "\n",
    "**Link to Dataset**\n",
    "`https://www.kaggle.com/pavanraj159/concrete-compressive-strength-data-set/`\n",
    "\n",
    "\n",
    "**Dataset Import Example**\n",
    "\n",
    "```python\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "df=pd.read_csv(\"compresive_strength_concrete.csv\")\n",
    "X=np.array(df[df.columns[:-1]])\n",
    "y=np.array(df[df.columns[-1]])\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-23.331213584903367 [ 0.11980433  0.10386581  0.08793432 -0.14991842  0.2922246   0.01808621\n",
      "  0.02019035  0.11422207] 0.001333808044849595 3.625694031020774\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "df=pd.read_csv(\"compresive_strength_concrete.csv\")\n",
    "x=np.array(df[df.columns[:-1]]) #Did I choose the wrong section of data to analyze?\n",
    "y=np.array(df[df.columns[-1]])\n",
    "# x=df[df.columns[0]]\n",
    "# y=df[df.columns[1]]\n",
    "\n",
    "N = df.size\n",
    "sumx = x.sum()\n",
    "sumy = y.sum()\n",
    "x_2 = x**2\n",
    "sumx_2 = x_2.sum()\n",
    "xy = x[:,0]*y\n",
    "sumxy = xy.sum()\n",
    "\n",
    "m_slope=(N*sumxy-sumx*sumy)/(N*sumx_2-sumx**2)\n",
    "bias=(sumy-m_slope*sumx)/N #3.625694031020774\n",
    "\n",
    "model = LinearRegression().fit(x,y)\n",
    "# m_slope = model.coef_\n",
    "# bias = model.intercept_\n",
    "\n",
    "# y_pos=x[:,0]*m_slope+bias\n",
    "\n",
    "# trueslope = df[2] #??\n",
    "\n",
    "# ygt=x[:,0]*trueslope\n",
    "\n",
    "print(model.intercept_, model.coef_, m_slope, bias) #Why are the coefficients in different data structures? Why is the bias different too?\n",
    "\n",
    "# yp=model.predict(x.reshape(-1,1))\n",
    "# tss=((y.mean()-y)**2).sum()\n",
    "# rss=((yp-y)**2).sum()\n",
    "# r2=1-rss/tss\n",
    "# print(r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "1. What could be the reason for the difference between the coefficients and or R^2?\n",
    "2. How many ways can we solve a linear regression problem and what are the advantages of each method?\n",
    "3. How good is your model based on its R^2 metric? Do you think you could improve it? If so how?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason for the differences between the two is caused by inaccuracies in the model causing the values to not be\n",
    "There are two ways to solve a linear regression problem and they are gradient descent which is easy to fit and process plus it works with all models and close-form which is faster and effective.\n",
    "The model probably could be improved by decreasing the amount of variance in the data. Higher R^2 metrics means a better model and vice versa for a low R^2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "1. What are the differences between classification and regression?\n",
    "2. What classifier are we going to examine in the next class?\n",
    "4. How is it similar to a linear regression?\n",
    "\n",
    "**Tip** You might have to read handout 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification involves trying to group a piece of data into a particular category rather than trying to predict a value like regression does.\n",
    "We are going to examine Decision trees in the next class which are similar to linear regression in that they share the same goal in trying to find the hyperplane of a data set to divide up the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
